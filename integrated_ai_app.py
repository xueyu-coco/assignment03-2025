import streamlit as st
from diffusers import DiffusionPipeline
import torch
from PIL import Image, ImageDraw
import io
import time
import os
import cv2
import numpy as np
import av
from streamlit_webrtc import webrtc_streamer

# Language configurations
LANGUAGES = {
    "English": {
        "page_title": "AI Creative Studio",
        "page_header": "ğŸ¨ AI Creative Studio",
        "page_subtitle": "### Your all-in-one AI creative toolkit",
        "sidebar_language": "ğŸŒ Language",
        "sidebar_navigation": "ğŸ“± Navigation",
        "nav_image_gen": "ğŸ¨ Image Generator",
        "nav_video_filter": "ğŸ“¹ Video Filter",
        
        # Image Generator
        "img_title": "ğŸ¨ AI Image Generator",
        "img_subtitle": "Transform text descriptions into beautiful images using Stable Diffusion",
        "sidebar_settings": "âš™ï¸ Generation Settings",
        "preset_prompts": "Choose preset prompt:",
        "advanced_settings": "ğŸ”§ Advanced Settings",
        "system_status": "ğŸ’» System Status",
        "input_description": "ğŸ“ Input Description",
        "generation_result": "ğŸ–¼ï¸ Generation Result",
        "prompt_label": "Image description (prompt):",
        "prompt_help": "Describe in detail what image you want to generate, including style, colors, composition, etc.",
        "negative_prompt_label": "Negative prompt (content to avoid):",
        "negative_prompt_help": "Describe what you don't want to appear in the image",
        "generate_button": "ğŸ¨ Generate Image",
        "steps_label": "Generation steps",
        "steps_help": "More steps usually produce better quality but take longer",
        "guidance_label": "Guidance scale",
        "guidance_help": "Controls how closely AI follows the prompt",
        "gpu_available": "GPU: ",
        "cuda_version": "CUDA Version: ",
        "gpu_unavailable": "GPU unavailable, using CPU",
        "gpu_enabled": "âœ… GPU acceleration enabled",
        "gpu_warning": "âš ï¸ Using CPU mode, generation will be slower",
        "model_error": "Model loading failed: ",
        "generation_error": "Image generation failed: ",
        "generating": "Generating image...",
        "generation_complete": "âœ… Generation complete! Time: ",
        "download_button": "ğŸ“¥ Download Image",
        "prompt_warning": "âš ï¸ Please enter an image description",
        "usage_instructions": "ğŸ“– Usage Instructions",
        "example_gallery": "ğŸ–¼ï¸ Example Gallery",
        "preset_landscape": "a beautiful landscape with mountains, lakes, and trees, golden hour lighting",
        "preset_animal": "a cute fluffy kitten playing in a garden, soft lighting, adorable",
        "preset_scifi": "futuristic cityscape with flying cars, neon lights, cyberpunk style",
        "preset_portrait": "portrait of a person, artistic style, detailed, professional lighting",
        "preset_cartoon": "cartoon style illustration, colorful, friendly, animated character",
        "negative_default": "blurry, low quality, distorted, ugly",
        "default_prompt": "a beautiful landscape with mountains",
        
        # Video Filter
        "video_title": "ğŸ­ Custom Image Video Filter",
        "video_subtitle": "Add your custom image at detected face locations in real-time video",
        "video_info1": "ğŸ“¹ Once the camera is enabled, the app will automatically detect faces and display your custom image at face locations",
        "video_info2": "ğŸ­ If no faces are detected, your custom image will appear in the center of the screen",
        "current_image": "ğŸ“¸ Current Image",
        "image_loaded": "âœ… Image loaded successfully",
        "image_not_found": "âŒ Image file not found",
        "fallback_warning": "Using fallback teddy dog image",
        "image_path_label": "Image Path:",
        "browse_button": "ğŸ“ Browse Image",
        "upload_image": "ğŸ“¤ Upload Image"
    },
    "ä¸­æ–‡": {
        "page_title": "AIåˆ›æ„å·¥ä½œå®¤",
        "page_header": "ğŸ¨ AIåˆ›æ„å·¥ä½œå®¤", 
        "page_subtitle": "### æ‚¨çš„ä¸€ä½“åŒ–AIåˆ›æ„å·¥å…·åŒ…",
        "sidebar_language": "ğŸŒ è¯­è¨€",
        "sidebar_navigation": "ğŸ“± å¯¼èˆª",
        "nav_image_gen": "ğŸ¨ å›¾åƒç”Ÿæˆå™¨",
        "nav_video_filter": "ğŸ“¹ è§†é¢‘æ»¤é•œ",
        
        # Image Generator
        "img_title": "ğŸ¨ AIå›¾åƒç”Ÿæˆå™¨",
        "img_subtitle": "ä½¿ç”¨Stable Diffusionå°†æ–‡æœ¬æè¿°è½¬æ¢ä¸ºç²¾ç¾å›¾åƒ",
        "sidebar_settings": "âš™ï¸ ç”Ÿæˆè®¾ç½®",
        "preset_prompts": "é€‰æ‹©é¢„è®¾æç¤ºè¯ï¼š",
        "advanced_settings": "ğŸ”§ é«˜çº§è®¾ç½®",
        "system_status": "ğŸ’» ç³»ç»ŸçŠ¶æ€",
        "input_description": "ğŸ“ è¾“å…¥æè¿°",
        "generation_result": "ğŸ–¼ï¸ ç”Ÿæˆç»“æœ",
        "prompt_label": "å›¾åƒæè¿°ï¼ˆæç¤ºè¯ï¼‰ï¼š",
        "prompt_help": "è¯¦ç»†æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„å›¾åƒï¼ŒåŒ…æ‹¬é£æ ¼ã€é¢œè‰²ã€æ„å›¾ç­‰",
        "negative_prompt_label": "è´Ÿé¢æç¤ºè¯ï¼ˆè¦é¿å…çš„å†…å®¹ï¼‰ï¼š",
        "negative_prompt_help": "æè¿°ä½ ä¸å¸Œæœ›åœ¨å›¾åƒä¸­å‡ºç°çš„å†…å®¹",
        "generate_button": "ğŸ¨ ç”Ÿæˆå›¾åƒ",
        "steps_label": "ç”Ÿæˆæ­¥æ•°",
        "steps_help": "æ›´å¤šæ­¥æ•°é€šå¸¸äº§ç”Ÿæ›´å¥½çš„è´¨é‡ï¼Œä½†éœ€è¦æ›´é•¿æ—¶é—´",
        "guidance_label": "å¼•å¯¼æ¯”ä¾‹",
        "guidance_help": "æ§åˆ¶AIéµå¾ªæç¤ºè¯çš„ç¨‹åº¦",
        "gpu_available": "GPU: ",
        "cuda_version": "CUDAç‰ˆæœ¬: ",
        "gpu_unavailable": "GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPU",
        "gpu_enabled": "âœ… GPUåŠ é€Ÿå·²å¯ç”¨",
        "gpu_warning": "âš ï¸ ä½¿ç”¨CPUæ¨¡å¼ï¼Œç”Ÿæˆé€Ÿåº¦è¾ƒæ…¢",
        "model_error": "æ¨¡å‹åŠ è½½å¤±è´¥: ",
        "generation_error": "å›¾åƒç”Ÿæˆå¤±è´¥: ",
        "generating": "æ­£åœ¨ç”Ÿæˆå›¾åƒ...",
        "generation_complete": "âœ… ç”Ÿæˆå®Œæˆï¼ç”¨æ—¶: ",
        "download_button": "ğŸ“¥ ä¸‹è½½å›¾åƒ",
        "prompt_warning": "âš ï¸ è¯·è¾“å…¥å›¾åƒæè¿°",
        "usage_instructions": "ğŸ“– ä½¿ç”¨è¯´æ˜",
        "example_gallery": "ğŸ–¼ï¸ ç¤ºä¾‹ç”»å»Š",
        "preset_landscape": "ç¾ä¸½çš„é£æ™¯ï¼Œæœ‰å±±å³°ã€æ¹–æ³Šå’Œæ ‘æœ¨ï¼Œé»„é‡‘æ—¶å…‰ç…§æ˜",
        "preset_animal": "å¯çˆ±çš„æ¯›èŒ¸èŒ¸å°çŒ«åœ¨èŠ±å›­é‡Œç©è€ï¼ŒæŸ”å’Œçš„å…‰çº¿ï¼Œadorable",
        "preset_scifi": "æœªæ¥ä¸»ä¹‰åŸå¸‚æ™¯è§‚ï¼Œæœ‰é£è¡Œæ±½è½¦ï¼Œéœ“è™¹ç¯ï¼Œèµ›åšæœ‹å…‹é£æ ¼",
        "preset_portrait": "äººç‰©è‚–åƒï¼Œè‰ºæœ¯é£æ ¼ï¼Œè¯¦ç»†ï¼Œä¸“ä¸šç…§æ˜",
        "preset_cartoon": "å¡é€šé£æ ¼æ’å›¾ï¼Œè‰²å½©é²œè‰³ï¼Œå‹å¥½ï¼ŒåŠ¨ç”»è§’è‰²",
        "negative_default": "æ¨¡ç³Šï¼Œä½è´¨é‡ï¼Œæ‰­æ›²ï¼Œä¸‘é™‹",
        "default_prompt": "ç¾ä¸½çš„å±±å³°é£æ™¯",
        
        # Video Filter
        "video_title": "ğŸ­ è‡ªå®šä¹‰å›¾åƒè§†é¢‘æ»¤é•œ",
        "video_subtitle": "åœ¨å®æ—¶è§†é¢‘ä¸­æ£€æµ‹åˆ°çš„äººè„¸ä½ç½®æ·»åŠ è‡ªå®šä¹‰å›¾åƒ",
        "video_info1": "ğŸ“¹ å¼€å¯æ‘„åƒå¤´åï¼Œåº”ç”¨ä¼šè‡ªåŠ¨æ£€æµ‹äººè„¸å¹¶åœ¨äººè„¸ä½ç½®æ˜¾ç¤ºè‡ªå®šä¹‰å›¾åƒ",
        "video_info2": "ğŸ­ å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°äººè„¸ï¼Œè‡ªå®šä¹‰å›¾åƒä¼šå‡ºç°åœ¨å±å¹•ä¸­å¤®",
        "current_image": "ğŸ“¸ å½“å‰å›¾åƒ",
        "image_loaded": "âœ… å›¾åƒåŠ è½½æˆåŠŸ",
        "image_not_found": "âŒ å›¾åƒæ–‡ä»¶æœªæ‰¾åˆ°",
        "fallback_warning": "ä½¿ç”¨å¤‡ç”¨æ³°è¿ªç‹—å›¾åƒ",
        "image_path_label": "å›¾åƒè·¯å¾„ï¼š",
        "browse_button": "ğŸ“ æµè§ˆå›¾åƒ",
        "upload_image": "ğŸ“¤ ä¸Šä¼ å›¾åƒ"
    },
    "ç²¤è¯­": {
        "page_title": "AIå‰µæ„å·¥ä½œå®¤",
        "page_header": "ğŸ¨ AIå‰µæ„å·¥ä½œå®¤",
        "page_subtitle": "### ä½ å˜…ä¸€é«”åŒ–AIå‰µæ„å·¥å…·åŒ…",
        "sidebar_language": "ğŸŒ èªè¨€",
        "sidebar_navigation": "ğŸ“± å°èˆª",
        "nav_image_gen": "ğŸ¨ åœ–åƒç”Ÿæˆå™¨",
        "nav_video_filter": "ğŸ“¹ è¦–é »æ¿¾é¡",
        
        # Image Generator
        "img_title": "ğŸ¨ AIåœ–åƒç”Ÿæˆå™¨",
        "img_subtitle": "ç”¨Stable Diffusionå°‡æ–‡å­—æè¿°è®Šæˆéšéšå˜…åœ–åƒ",
        "sidebar_settings": "âš™ï¸ ç”Ÿæˆè¨­å®š",
        "preset_prompts": "æ€é è¨­æç¤ºè©ï¼š",
        "advanced_settings": "ğŸ”§ é€²éšè¨­å®š",
        "system_status": "ğŸ’» ç³»çµ±ç‹€æ…‹",
        "input_description": "ğŸ“ è¼¸å…¥æè¿°",
        "generation_result": "ğŸ–¼ï¸ ç”Ÿæˆçµæœ",
        "prompt_label": "åœ–åƒæè¿°ï¼ˆæç¤ºè©ï¼‰ï¼š",
        "prompt_help": "è©³ç´°æè¿°ä½ æƒ³è¦ç”Ÿæˆå˜…åœ–åƒï¼ŒåŒ…æ‹¬é¢¨æ ¼ã€é¡è‰²ã€æ§‹åœ–ç­‰",
        "negative_prompt_label": "è² é¢æç¤ºè©ï¼ˆè¦é¿å…å˜…å…§å®¹ï¼‰ï¼š",
        "negative_prompt_help": "æè¿°ä½ å””æƒ³å–ºåœ–åƒå…¥é¢å‡ºç¾å˜…å…§å®¹",
        "generate_button": "ğŸ¨ ç”Ÿæˆåœ–åƒ",
        "steps_label": "ç”Ÿæˆæ­¥æ•¸",
        "steps_help": "æ›´å¤šæ­¥æ•¸é€šå¸¸ç”¢ç”Ÿæ›´å¥½å˜…è³ªé‡ï¼Œä½†éœ€è¦æ›´é•·æ™‚é–“",
        "guidance_label": "å¼•å°æ¯”ä¾‹",
        "guidance_help": "æ§åˆ¶AIè·Ÿå¾æç¤ºè©å˜…ç¨‹åº¦",
        "gpu_available": "GPU: ",
        "cuda_version": "CUDAç‰ˆæœ¬: ",
        "gpu_unavailable": "GPUå””å¯ç”¨ï¼Œç”¨CPU",
        "gpu_enabled": "âœ… GPUåŠ é€Ÿå·²å•Ÿç”¨",
        "gpu_warning": "âš ï¸ ç”¨ç·ŠCPUæ¨¡å¼ï¼Œç”Ÿæˆé€Ÿåº¦æ¯”è¼ƒæ…¢",
        "model_error": "æ¨¡å‹åŠ è¼‰å¤±æ•—: ",
        "generation_error": "åœ–åƒç”Ÿæˆå¤±æ•—: ",
        "generating": "æ­£åœ¨ç”Ÿæˆåœ–åƒ...",
        "generation_complete": "âœ… ç”Ÿæˆå®Œæˆï¼ç”¨æ™‚: ",
        "download_button": "ğŸ“¥ ä¸‹è¼‰åœ–åƒ",
        "prompt_warning": "âš ï¸ è«‹è¼¸å…¥åœ–åƒæè¿°",
        "usage_instructions": "ğŸ“– ä½¿ç”¨èªªæ˜",
        "example_gallery": "ğŸ–¼ï¸ ç¤ºä¾‹ç•«å»Š",
        "preset_landscape": "éšéšå˜…é¢¨æ™¯ï¼Œæœ‰å±±å³°ã€æ¹–æ³ŠåŒæ¨¹æœ¨ï¼Œé»ƒé‡‘æ™‚å…‰ç…§æ˜",
        "preset_animal": "å¯æ„›å˜…æ¯›èŒ¸èŒ¸å°è²“å–ºèŠ±åœ’å…¥é¢ç©ï¼ŒæŸ”å’Œå˜…å…‰ç·šï¼Œadorable",
        "preset_scifi": "æœªä¾†ä¸»ç¾©åŸå¸‚æ™¯è§€ï¼Œæœ‰é£›è¡Œæ±½è»Šï¼Œéœ“è™¹ç‡ˆï¼Œè³½åšæœ‹å…‹é¢¨æ ¼",
        "preset_portrait": "äººç‰©è‚–åƒï¼Œè—è¡“é¢¨æ ¼ï¼Œè©³ç´°ï¼Œå°ˆæ¥­ç…§æ˜",
        "preset_cartoon": "å¡é€šé¢¨æ ¼æ’åœ–ï¼Œè‰²å½©é®®è‰·ï¼Œå‹å¥½ï¼Œå‹•ç•«è§’è‰²",
        "negative_default": "æ¨¡ç³Šï¼Œä½è³ªé‡ï¼Œæ‰­æ›²ï¼Œé†œæ¨£",
        "default_prompt": "éšéšå˜…å±±å³°é¢¨æ™¯",
        
        # Video Filter
        "video_title": "ğŸ­ è‡ªå®šç¾©åœ–åƒè¦–é »æ¿¾é¡",
        "video_subtitle": "å–ºå¯¦æ™‚è¦–é »ä¸­æª¢æ¸¬åˆ°å˜…äººè‡‰ä½ç½®æ·»åŠ è‡ªå®šç¾©åœ–åƒ",
        "video_info1": "ğŸ“¹ é–‹å•Ÿæ”åƒé ­å¾Œï¼Œæ‡‰ç”¨æœƒè‡ªå‹•æª¢æ¸¬äººè‡‰ä¸¦å–ºäººè‡‰ä½ç½®é¡¯ç¤ºè‡ªå®šç¾©åœ–åƒ",
        "video_info2": "ğŸ­ å¦‚æœå†‡æª¢æ¸¬åˆ°äººè‡‰ï¼Œè‡ªå®šç¾©åœ–åƒæœƒå‡ºç¾å–ºå±å¹•ä¸­å¤®",
        "current_image": "ğŸ“¸ ç•¶å‰åœ–åƒ",
        "image_loaded": "âœ… åœ–åƒåŠ è¼‰æˆåŠŸ",
        "image_not_found": "âŒ åœ–åƒæ–‡ä»¶æœªæµåˆ°",
        "fallback_warning": "ä½¿ç”¨å‚™ç”¨æ³°è¿ªç‹—åœ–åƒ",
        "image_path_label": "åœ–åƒè·¯å¾‘ï¼š",
        "browse_button": "ğŸ“ ç€è¦½åœ–åƒ",
        "upload_image": "ğŸ“¤ ä¸Šå‚³åœ–åƒ"
    }
}

# Page configuration
st.set_page_config(
    page_title="AI Creative Studio",
    page_icon="ğŸ¨",
    layout="wide"
)

# Load custom image from file for video filter
def load_custom_image(image_path, size=(100, 100)):
    """Load and process custom image for overlay"""
    try:
        if os.path.exists(image_path):
            img = Image.open(image_path)
            if img.mode != 'RGBA':
                img = img.convert('RGBA')
            img = img.resize(size, Image.Resampling.LANCZOS)
            return img
        else:
            return create_teddy_dog_image(size)
    except Exception as e:
        return create_teddy_dog_image(size)

# Fallback teddy dog image creation
def create_teddy_dog_image(size=(100, 100)):
    """Create a simple teddy dog avatar"""
    img = Image.new('RGBA', size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    head_size = min(size) * 0.8
    head_x = size[0] // 2
    head_y = size[1] // 2
    head_radius = head_size // 2
    
    # Draw head
    draw.ellipse([
        head_x - head_radius, head_y - head_radius,
        head_x + head_radius, head_y + head_radius
    ], fill=(139, 90, 43, 255))
    
    # Draw ears
    ear_size = head_radius * 0.4
    draw.ellipse([
        head_x - head_radius * 0.8 - ear_size//2, head_y - head_radius * 0.8 - ear_size//2,
        head_x - head_radius * 0.8 + ear_size//2, head_y - head_radius * 0.8 + ear_size//2
    ], fill=(101, 67, 33, 255))
    draw.ellipse([
        head_x + head_radius * 0.8 - ear_size//2, head_y - head_radius * 0.8 - ear_size//2,
        head_x + head_radius * 0.8 + ear_size//2, head_y - head_radius * 0.8 + ear_size//2
    ], fill=(101, 67, 33, 255))
    
    # Draw eyes
    eye_size = head_radius * 0.15
    draw.ellipse([
        head_x - head_radius * 0.3 - eye_size, head_y - head_radius * 0.2 - eye_size,
        head_x - head_radius * 0.3 + eye_size, head_y - head_radius * 0.2 + eye_size
    ], fill=(0, 0, 0, 255))
    draw.ellipse([
        head_x + head_radius * 0.3 - eye_size, head_y - head_radius * 0.2 - eye_size,
        head_x + head_radius * 0.3 + eye_size, head_y - head_radius * 0.2 + eye_size
    ], fill=(0, 0, 0, 255))
    
    # Draw nose
    nose_size = head_radius * 0.1
    draw.ellipse([
        head_x - nose_size, head_y + head_radius * 0.1 - nose_size,
        head_x + nose_size, head_y + head_radius * 0.1 + nose_size
    ], fill=(0, 0, 0, 255))
    
    # Draw mouth
    mouth_width = head_radius * 0.3
    draw.arc([
        head_x - mouth_width, head_y + head_radius * 0.2,
        head_x + mouth_width, head_y + head_radius * 0.4
    ], start=0, end=180, fill=(0, 0, 0, 255), width=3)
    
    return img

# Initialize model for image generation
@st.cache_resource
def load_model():
    """Load and cache Stable Diffusion model"""
    try:
        pipe = DiffusionPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
        )
        if torch.cuda.is_available():
            pipe = pipe.to("cuda")
        return pipe
    except Exception as e:
        return None

def generate_image(pipe, prompt, negative_prompt="", steps=20, guidance_scale=7.5):
    """Generate image"""
    try:
        with torch.autocast("cuda" if torch.cuda.is_available() else "cpu"):
            result = pipe(
                prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=steps,
                guidance_scale=guidance_scale
            )
            return result.images[0]
    except Exception as e:
        return None

# Video filter functions
def overlay_custom_image(img, x, y, scale=1.0, overlay_array=None):
    """Overlay custom image at specified position"""
    if overlay_array is None:
        return img
        
    img_height, img_width = overlay_array.shape[:2]
    new_height = int(img_height * scale)
    new_width = int(img_width * scale)
    
    if new_height <= 0 or new_width <= 0:
        return img
    
    resized_img = cv2.resize(overlay_array, (new_width, new_height))
    
    y1 = max(0, y - new_height // 2)
    y2 = min(img.shape[0], y1 + new_height)
    x1 = max(0, x - new_width // 2)
    x2 = min(img.shape[1], x1 + new_width)
    
    actual_height = y2 - y1
    actual_width = x2 - x1
    
    if actual_height <= 0 or actual_width <= 0:
        return img
    
    img_roi = resized_img[:actual_height, :actual_width]
    
    if img_roi.shape[2] == 4:  # RGBA
        alpha = img_roi[:, :, 3] / 255.0
        for c in range(3):  # BGR
            img[y1:y2, x1:x2, c] = (
                alpha * img_roi[:, :, c] + 
                (1 - alpha) * img[y1:y2, x1:x2, c]
            )
    else:  # RGB
        img[y1:y2, x1:x2] = img_roi[:, :, :3]
    
    return img

def main():
    # Initialize session state
    if 'language' not in st.session_state:
        st.session_state.language = "English"
    if 'page' not in st.session_state:
        st.session_state.page = "Image Generator"
    if 'custom_image_path' not in st.session_state:
        st.session_state.custom_image_path = r"C:\Users\lxy\Desktop\1624425308015_5589c28e_29447(1).png"
    
    # Get current language texts
    texts = LANGUAGES[st.session_state.language]
    
    # Title and description
    st.title(texts["page_header"])
    st.markdown(texts["page_subtitle"])
    
    # Sidebar
    with st.sidebar:
        # Language selector
        st.header(texts["sidebar_language"])
        language = st.selectbox(
            "Select Language / é€‰æ‹©è¯­è¨€ / æ€èªè¨€:",
            ["English", "ä¸­æ–‡", "ç²¤è¯­"],
            index=["English", "ä¸­æ–‡", "ç²¤è¯­"].index(st.session_state.language)
        )
        
        if language != st.session_state.language:
            st.session_state.language = language
            st.rerun()
        
        st.header(texts["sidebar_navigation"])
        page = st.selectbox(
            "Choose Function:",
            [texts["nav_image_gen"], texts["nav_video_filter"]]
        )
        
        # Update page state
        if page == texts["nav_image_gen"]:
            st.session_state.page = "Image Generator"
        else:
            st.session_state.page = "Video Filter"
    
    # Main content based on selected page
    if st.session_state.page == "Image Generator":
        show_image_generator(texts)
    else:
        show_video_filter(texts)

def show_image_generator(texts):
    """Display the image generator interface"""
    st.header(texts["img_title"])
    st.markdown(f"### {texts['img_subtitle']}")
    
    with st.sidebar:
        st.header(texts["sidebar_settings"])
        
        # Preset prompts
        preset_prompts = {
            "Select preset...": "",
            "Beautiful Landscape": texts["preset_landscape"],
            "Cute Animal": texts["preset_animal"],
            "Sci-fi Scene": texts["preset_scifi"],
            "Art Portrait": texts["preset_portrait"],
            "Cartoon Style": texts["preset_cartoon"]
        }
        
        selected_preset = st.selectbox(texts["preset_prompts"], list(preset_prompts.keys()))
        
        # Advanced settings
        st.subheader(texts["advanced_settings"])
        steps = st.slider(texts["steps_label"], min_value=10, max_value=50, value=20, 
                         help=texts["steps_help"])
        guidance_scale = st.slider(texts["guidance_label"], min_value=1.0, max_value=20.0, value=7.5, step=0.5,
                                 help=texts["guidance_help"])
        
        # GPU status display
        st.subheader(texts["system_status"])
        if torch.cuda.is_available():
            st.success(f"{texts['gpu_available']}{torch.cuda.get_device_name(0)}")
            st.info(f"{texts['cuda_version']}{torch.version.cuda}")
        else:
            st.warning(texts["gpu_unavailable"])
    
    # Main interface
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader(texts["input_description"])
        
        # Main prompt
        if selected_preset != "Select preset...":
            default_prompt = preset_prompts[selected_preset]
        else:
            default_prompt = texts["default_prompt"]
            
        prompt = st.text_area(
            texts["prompt_label"], 
            value=default_prompt,
            height=100,
            help=texts["prompt_help"]
        )
        
        # Negative prompt
        negative_prompt = st.text_area(
            texts["negative_prompt_label"],
            value=texts["negative_default"],
            height=60,
            help=texts["negative_prompt_help"]
        )
        
        # Generate button
        generate_button = st.button(texts["generate_button"], type="primary", use_container_width=True)
    
    with col2:
        st.subheader(texts["generation_result"])
        
        # Create placeholders for displaying images
        image_placeholder = st.empty()
        info_placeholder = st.empty()
        download_placeholder = st.empty()
    
    # Handle generation request
    if generate_button and prompt.strip():
        # Load model
        pipe = load_model()
        
        if pipe is not None:
            # Show progress
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text(texts["generating"])
            start_time = time.time()
            
            # Simulate progress updates
            for i in range(steps):
                progress_bar.progress((i + 1) / steps)
                time.sleep(0.1)
            
            # Generate image
            image = generate_image(pipe, prompt, negative_prompt, steps, guidance_scale)
            
            if image is not None:
                # Calculate generation time
                generation_time = time.time() - start_time
                
                # Display image
                with col2:
                    image_placeholder.image(image, caption=prompt, use_container_width=True)
                    
                    # Show information
                    info_placeholder.info(f"{texts['generation_complete']}{generation_time:.2f}s")
                    
                    # Prepare download
                    img_buffer = io.BytesIO()
                    image.save(img_buffer, format='PNG')
                    img_data = img_buffer.getvalue()
                    
                    # Download button
                    download_placeholder.download_button(
                        label=texts["download_button"],
                        data=img_data,
                        file_name=f"ai_generated_{int(time.time())}.png",
                        mime="image/png",
                        use_container_width=True
                    )
            
            # Clear progress display
            progress_bar.empty()
            status_text.empty()
    
    elif generate_button and not prompt.strip():
        st.warning(texts["prompt_warning"])

def show_video_filter(texts):
    """Display the video filter interface"""
    st.header(texts["video_title"])
    st.markdown(f"### {texts['video_subtitle']}")
    
    # Control options
    col1, col2 = st.columns(2)
    
    with col1:
        st.info(texts["video_info1"])
    
    with col2:
        st.info(texts["video_info2"])
    
    # Image upload/selection section
    with st.sidebar:
        st.header(texts["current_image"])
        
        # File uploader
        uploaded_file = st.file_uploader(
            texts["upload_image"],
            type=['png', 'jpg', 'jpeg', 'gif', 'bmp'],
            accept_multiple_files=False
        )
        
        # Use uploaded file or default path
        if uploaded_file is not None:
            # Save uploaded file temporarily
            temp_path = f"temp_{uploaded_file.name}"
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            current_image_path = temp_path
            st.success(texts["image_loaded"])
        else:
            current_image_path = st.session_state.custom_image_path
            st.text(f"{texts['image_path_label']}")
            st.code(current_image_path)
        
        # Check if image exists and show preview
        if os.path.exists(current_image_path):
            st.success(texts["image_loaded"])
            try:
                preview_img = Image.open(current_image_path)
                preview_img.thumbnail((150, 150))
                st.image(preview_img, caption="Image Preview")
            except Exception as e:
                st.error(f"Error loading image: {e}")
        else:
            st.error(texts["image_not_found"])
            st.warning(texts["fallback_warning"])
    
    # Load the overlay image
    overlay_img = load_custom_image(current_image_path if os.path.exists(current_image_path) else "")
    overlay_array = np.array(overlay_img)
    
    # Video frame callback function
    def video_frame_callback(frame):
        img = frame.to_ndarray(format="bgr24")
        
        try:
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            
            # Add custom image at each detected face location
            for (x, y, w, h) in faces:
                center_x = x + w // 2
                center_y = y + h // 2
                scale = w / 100.0
                img = overlay_custom_image(img, center_x, center_y, scale, overlay_array)
        
        except Exception as e:
            # If face detection fails, add image in center
            center_x = img.shape[1] // 2
            center_y = img.shape[0] // 2
            img = overlay_custom_image(img, center_x, center_y, 1.5, overlay_array)
        
        return av.VideoFrame.from_ndarray(img, format="bgr24")
    
    # Video stream component
    webrtc_streamer(
        key="integrated_video_filter",
        video_frame_callback=video_frame_callback,
        rtc_configuration={
            "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
        }
    )
    
    # Usage instructions
    with st.expander(texts["usage_instructions"]):
        st.markdown(f"""
        ### {texts["usage_instructions"]}:
        
        **{texts["nav_image_gen"]}:**
        - {texts["img_subtitle"]}
        - {texts["prompt_help"]}
        
        **{texts["nav_video_filter"]}:**
        - {texts["video_subtitle"]}
        - {texts["video_info1"]}
        - {texts["video_info2"]}
        """)

if __name__ == "__main__":
    main()