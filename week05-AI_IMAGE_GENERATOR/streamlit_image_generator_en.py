import streamlit as st
from diffusers import DiffusionPipeline
import torch
from PIL import Image
import io
import time

# Language configurations
LANGUAGES = {
    "English": {
        "page_title": "AI Image Generator",
        "page_header": "ğŸ¨ AI Image Generator",
        "page_subtitle": "### Transform text descriptions into beautiful images using Stable Diffusion",
        "sidebar_settings": "âš™ï¸ Generation Settings",
        "sidebar_language": "ğŸŒ Language",
        "preset_prompts": "Choose preset prompt:",
        "advanced_settings": "ğŸ”§ Advanced Settings",
        "system_status": "ğŸ’» System Status",
        "input_description": "ğŸ“ Input Description",
        "generation_result": "ğŸ–¼ï¸ Generation Result",
        "prompt_label": "Image description (prompt):",
        "prompt_help": "Describe in detail what image you want to generate, including style, colors, composition, etc.",
        "negative_prompt_label": "Negative prompt (content to avoid):",
        "negative_prompt_help": "Describe what you don't want to appear in the image",
        "generate_button": "ğŸ¨ Generate Image",
        "steps_label": "Generation steps",
        "steps_help": "More steps usually produce better quality but take longer",
        "guidance_label": "Guidance scale",
        "guidance_help": "Controls how closely AI follows the prompt",
        "gpu_available": "GPU: ",
        "cuda_version": "CUDA Version: ",
        "gpu_unavailable": "GPU unavailable, using CPU",
        "gpu_enabled": "âœ… GPU acceleration enabled",
        "gpu_warning": "âš ï¸ Using CPU mode, generation will be slower",
        "model_error": "Model loading failed: ",
        "generation_error": "Image generation failed: ",
        "generating": "Generating image...",
        "generation_complete": "âœ… Generation complete! Time: ",
        "download_button": "ğŸ“¥ Download Image",
        "prompt_warning": "âš ï¸ Please enter an image description",
        "usage_instructions": "ğŸ“– Usage Instructions",
        "example_gallery": "ğŸ–¼ï¸ Example Gallery",
        "preset_landscape": "a beautiful landscape with mountains, lakes, and trees, golden hour lighting",
        "preset_animal": "a cute fluffy kitten playing in a garden, soft lighting, adorable",
        "preset_scifi": "futuristic cityscape with flying cars, neon lights, cyberpunk style",
        "preset_portrait": "portrait of a person, artistic style, detailed, professional lighting",
        "preset_cartoon": "cartoon style illustration, colorful, friendly, animated character",
        "negative_default": "blurry, low quality, distorted, ugly",
        "default_prompt": "a beautiful landscape with mountains"
    },
    "ä¸­æ–‡": {
        "page_title": "AIå›¾åƒç”Ÿæˆå™¨",
        "page_header": "ğŸ¨ AIå›¾åƒç”Ÿæˆå™¨",
        "page_subtitle": "### ä½¿ç”¨Stable Diffusionå°†æ–‡æœ¬æè¿°è½¬æ¢ä¸ºç²¾ç¾å›¾åƒ",
        "sidebar_settings": "âš™ï¸ ç”Ÿæˆè®¾ç½®",
        "sidebar_language": "ğŸŒ è¯­è¨€",
        "preset_prompts": "é€‰æ‹©é¢„è®¾æç¤ºè¯ï¼š",
        "advanced_settings": "ğŸ”§ é«˜çº§è®¾ç½®",
        "system_status": "ğŸ’» ç³»ç»ŸçŠ¶æ€",
        "input_description": "ğŸ“ è¾“å…¥æè¿°",
        "generation_result": "ğŸ–¼ï¸ ç”Ÿæˆç»“æœ",
        "prompt_label": "å›¾åƒæè¿°ï¼ˆæç¤ºè¯ï¼‰ï¼š",
        "prompt_help": "è¯¦ç»†æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„å›¾åƒï¼ŒåŒ…æ‹¬é£æ ¼ã€é¢œè‰²ã€æ„å›¾ç­‰",
        "negative_prompt_label": "è´Ÿé¢æç¤ºè¯ï¼ˆè¦é¿å…çš„å†…å®¹ï¼‰ï¼š",
        "negative_prompt_help": "æè¿°ä½ ä¸å¸Œæœ›åœ¨å›¾åƒä¸­å‡ºç°çš„å†…å®¹",
        "generate_button": "ğŸ¨ ç”Ÿæˆå›¾åƒ",
        "steps_label": "ç”Ÿæˆæ­¥æ•°",
        "steps_help": "æ›´å¤šæ­¥æ•°é€šå¸¸äº§ç”Ÿæ›´å¥½çš„è´¨é‡ï¼Œä½†éœ€è¦æ›´é•¿æ—¶é—´",
        "guidance_label": "å¼•å¯¼æ¯”ä¾‹",
        "guidance_help": "æ§åˆ¶AIéµå¾ªæç¤ºè¯çš„ç¨‹åº¦",
        "gpu_available": "GPU: ",
        "cuda_version": "CUDAç‰ˆæœ¬: ",
        "gpu_unavailable": "GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPU",
        "gpu_enabled": "âœ… GPUåŠ é€Ÿå·²å¯ç”¨",
        "gpu_warning": "âš ï¸ ä½¿ç”¨CPUæ¨¡å¼ï¼Œç”Ÿæˆé€Ÿåº¦è¾ƒæ…¢",
        "model_error": "æ¨¡å‹åŠ è½½å¤±è´¥: ",
        "generation_error": "å›¾åƒç”Ÿæˆå¤±è´¥: ",
        "generating": "æ­£åœ¨ç”Ÿæˆå›¾åƒ...",
        "generation_complete": "âœ… ç”Ÿæˆå®Œæˆï¼ç”¨æ—¶: ",
        "download_button": "ğŸ“¥ ä¸‹è½½å›¾åƒ",
        "prompt_warning": "âš ï¸ è¯·è¾“å…¥å›¾åƒæè¿°",
        "usage_instructions": "ğŸ“– ä½¿ç”¨è¯´æ˜",
        "example_gallery": "ğŸ–¼ï¸ ç¤ºä¾‹ç”»å»Š",
        "preset_landscape": "ç¾ä¸½çš„é£æ™¯ï¼Œæœ‰å±±å³°ã€æ¹–æ³Šå’Œæ ‘æœ¨ï¼Œé»„é‡‘æ—¶å…‰ç…§æ˜",
        "preset_animal": "å¯çˆ±çš„æ¯›èŒ¸èŒ¸å°çŒ«åœ¨èŠ±å›­é‡Œç©è€ï¼ŒæŸ”å’Œçš„å…‰çº¿ï¼Œadorable",
        "preset_scifi": "æœªæ¥ä¸»ä¹‰åŸå¸‚æ™¯è§‚ï¼Œæœ‰é£è¡Œæ±½è½¦ï¼Œéœ“è™¹ç¯ï¼Œèµ›åšæœ‹å…‹é£æ ¼",
        "preset_portrait": "äººç‰©è‚–åƒï¼Œè‰ºæœ¯é£æ ¼ï¼Œè¯¦ç»†ï¼Œä¸“ä¸šç…§æ˜",
        "preset_cartoon": "å¡é€šé£æ ¼æ’å›¾ï¼Œè‰²å½©é²œè‰³ï¼Œå‹å¥½ï¼ŒåŠ¨ç”»è§’è‰²",
        "negative_default": "æ¨¡ç³Šï¼Œä½è´¨é‡ï¼Œæ‰­æ›²ï¼Œä¸‘é™‹",
        "default_prompt": "ç¾ä¸½çš„å±±å³°é£æ™¯"
    },
    "ç²¤è¯­": {
        "page_title": "AIåœ–åƒç”Ÿæˆå™¨",
        "page_header": "ğŸ¨ AIåœ–åƒç”Ÿæˆå™¨",
        "page_subtitle": "### ç”¨Stable Diffusionå°‡æ–‡å­—æè¿°è®Šæˆéšéšå˜…åœ–åƒ",
        "sidebar_settings": "âš™ï¸ ç”Ÿæˆè¨­å®š",
        "sidebar_language": "ğŸŒ èªè¨€",
        "preset_prompts": "æ€é è¨­æç¤ºè©ï¼š",
        "advanced_settings": "ğŸ”§ é€²éšè¨­å®š",
        "system_status": "ğŸ’» ç³»çµ±ç‹€æ…‹",
        "input_description": "ğŸ“ è¼¸å…¥æè¿°",
        "generation_result": "ğŸ–¼ï¸ ç”Ÿæˆçµæœ",
        "prompt_label": "åœ–åƒæè¿°ï¼ˆæç¤ºè©ï¼‰ï¼š",
        "prompt_help": "è©³ç´°æè¿°ä½ æƒ³è¦ç”Ÿæˆå˜…åœ–åƒï¼ŒåŒ…æ‹¬é¢¨æ ¼ã€é¡è‰²ã€æ§‹åœ–ç­‰",
        "negative_prompt_label": "è² é¢æç¤ºè©ï¼ˆè¦é¿å…å˜…å…§å®¹ï¼‰ï¼š",
        "negative_prompt_help": "æè¿°ä½ å””æƒ³å–ºåœ–åƒå…¥é¢å‡ºç¾å˜…å…§å®¹",
        "generate_button": "ğŸ¨ ç”Ÿæˆåœ–åƒ",
        "steps_label": "ç”Ÿæˆæ­¥æ•¸",
        "steps_help": "æ›´å¤šæ­¥æ•¸é€šå¸¸ç”¢ç”Ÿæ›´å¥½å˜…è³ªé‡ï¼Œä½†éœ€è¦æ›´é•·æ™‚é–“",
        "guidance_label": "å¼•å°æ¯”ä¾‹",
        "guidance_help": "æ§åˆ¶AIè·Ÿå¾æç¤ºè©å˜…ç¨‹åº¦",
        "gpu_available": "GPU: ",
        "cuda_version": "CUDAç‰ˆæœ¬: ",
        "gpu_unavailable": "GPUå””å¯ç”¨ï¼Œç”¨CPU",
        "gpu_enabled": "âœ… GPUåŠ é€Ÿå·²å•Ÿç”¨",
        "gpu_warning": "âš ï¸ ç”¨ç·ŠCPUæ¨¡å¼ï¼Œç”Ÿæˆé€Ÿåº¦æ¯”è¼ƒæ…¢",
        "model_error": "æ¨¡å‹åŠ è¼‰å¤±æ•—: ",
        "generation_error": "åœ–åƒç”Ÿæˆå¤±æ•—: ",
        "generating": "æ­£åœ¨ç”Ÿæˆåœ–åƒ...",
        "generation_complete": "âœ… ç”Ÿæˆå®Œæˆï¼ç”¨æ™‚: ",
        "download_button": "ğŸ“¥ ä¸‹è¼‰åœ–åƒ",
        "prompt_warning": "âš ï¸ è«‹è¼¸å…¥åœ–åƒæè¿°",
        "usage_instructions": "ğŸ“– ä½¿ç”¨èªªæ˜",
        "example_gallery": "ğŸ–¼ï¸ ç¤ºä¾‹ç•«å»Š",
        "preset_landscape": "éšéšå˜…é¢¨æ™¯ï¼Œæœ‰å±±å³°ã€æ¹–æ³ŠåŒæ¨¹æœ¨ï¼Œé»ƒé‡‘æ™‚å…‰ç…§æ˜",
        "preset_animal": "å¯æ„›å˜…æ¯›èŒ¸èŒ¸å°è²“å–ºèŠ±åœ’å…¥é¢ç©ï¼ŒæŸ”å’Œå˜…å…‰ç·šï¼Œadorable",
        "preset_scifi": "æœªä¾†ä¸»ç¾©åŸå¸‚æ™¯è§€ï¼Œæœ‰é£›è¡Œæ±½è»Šï¼Œéœ“è™¹ç‡ˆï¼Œè³½åšæœ‹å…‹é¢¨æ ¼",
        "preset_portrait": "äººç‰©è‚–åƒï¼Œè—è¡“é¢¨æ ¼ï¼Œè©³ç´°ï¼Œå°ˆæ¥­ç…§æ˜",
        "preset_cartoon": "å¡é€šé¢¨æ ¼æ’åœ–ï¼Œè‰²å½©é®®è‰·ï¼Œå‹å¥½ï¼Œå‹•ç•«è§’è‰²",
        "negative_default": "æ¨¡ç³Šï¼Œä½è³ªé‡ï¼Œæ‰­æ›²ï¼Œé†œæ¨£",
        "default_prompt": "éšéšå˜…å±±å³°é¢¨æ™¯"
    }
}

# Page configuration
st.set_page_config(
    page_title="AI Image Generator",
    page_icon="ğŸ¨",
    layout="wide"
)

# Initialize model
@st.cache_resource
def load_model():
    """Load and cache Stable Diffusion model"""
    try:
        pipe = DiffusionPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
        )
        if torch.cuda.is_available():
            pipe = pipe.to("cuda")
            # Get current language for success message
            if 'language' in st.session_state:
                texts = LANGUAGES[st.session_state.language]
                st.success(texts["gpu_enabled"])
            else:
                st.success("âœ… GPU acceleration enabled")
        else:
            # Get current language for warning message
            if 'language' in st.session_state:
                texts = LANGUAGES[st.session_state.language]
                st.warning(texts["gpu_warning"])
            else:
                st.warning("âš ï¸ Using CPU mode, generation will be slower")
        return pipe
    except Exception as e:
        # Get current language for error message
        if 'language' in st.session_state:
            texts = LANGUAGES[st.session_state.language]
            st.error(f"{texts['model_error']}{e}")
        else:
            st.error(f"Model loading failed: {e}")
        return None

def generate_image(pipe, prompt, negative_prompt="", steps=20, guidance_scale=7.5):
    """Generate image"""
    try:
        with torch.autocast("cuda" if torch.cuda.is_available() else "cpu"):
            result = pipe(
                prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=steps,
                guidance_scale=guidance_scale
            )
            return result.images[0]
    except Exception as e:
        # Get current language for error message
        if 'language' in st.session_state:
            texts = LANGUAGES[st.session_state.language]
            st.error(f"{texts['generation_error']}{e}")
        else:
            st.error(f"Image generation failed: {e}")
        return None

def main():
    # Initialize session state for language
    if 'language' not in st.session_state:
        st.session_state.language = "English"
    
    # Get current language texts
    texts = LANGUAGES[st.session_state.language]
    
    # Title and description
    st.title(texts["page_header"])
    st.markdown(texts["page_subtitle"])
    
    # Sidebar settings
    with st.sidebar:
        # Language selector at the top
        st.header(texts["sidebar_language"])
        language = st.selectbox(
            "Select Language / é€‰æ‹©è¯­è¨€ / æ€èªè¨€:",
            ["English", "ä¸­æ–‡", "ç²¤è¯­"],
            index=["English", "ä¸­æ–‡", "ç²¤è¯­"].index(st.session_state.language)
        )
        
        # Update session state if language changed
        if language != st.session_state.language:
            st.session_state.language = language
            st.rerun()
        
        st.header(texts["sidebar_settings"])
        
        # Preset prompts
        preset_prompts = {
            "Select preset...": "",
            "Beautiful Landscape": texts["preset_landscape"],
            "Cute Animal": texts["preset_animal"],
            "Sci-fi Scene": texts["preset_scifi"],
            "Art Portrait": texts["preset_portrait"],
            "Cartoon Style": texts["preset_cartoon"]
        }
        
        selected_preset = st.selectbox(texts["preset_prompts"], list(preset_prompts.keys()))
        
        # Advanced settings
        st.subheader(texts["advanced_settings"])
        steps = st.slider(texts["steps_label"], min_value=10, max_value=50, value=20, 
                         help=texts["steps_help"])
        guidance_scale = st.slider(texts["guidance_label"], min_value=1.0, max_value=20.0, value=7.5, step=0.5,
                                 help=texts["guidance_help"])
        
        # GPU status display
        st.subheader(texts["system_status"])
        if torch.cuda.is_available():
            st.success(f"{texts['gpu_available']}{torch.cuda.get_device_name(0)}")
            st.info(f"{texts['cuda_version']}{torch.version.cuda}")
        else:
            st.warning(texts["gpu_unavailable"])
    
    # Main interface
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader(texts["input_description"])
        
        # Main prompt
        if selected_preset != "Select preset...":
            default_prompt = preset_prompts[selected_preset]
        else:
            default_prompt = texts["default_prompt"]
            
        prompt = st.text_area(
            texts["prompt_label"], 
            value=default_prompt,
            height=100,
            help=texts["prompt_help"]
        )
        
        # Negative prompt
        negative_prompt = st.text_area(
            texts["negative_prompt_label"],
            value=texts["negative_default"],
            height=60,
            help=texts["negative_prompt_help"]
        )
        
        # Generate button
        generate_button = st.button(texts["generate_button"], type="primary", use_container_width=True)
    
    with col2:
        st.subheader(texts["generation_result"])
        
        # Create placeholders for displaying images
        image_placeholder = st.empty()
        info_placeholder = st.empty()
        download_placeholder = st.empty()
    
    # Handle generation request
    if generate_button and prompt.strip():
        # Load model
        pipe = load_model()
        
        if pipe is not None:
            # Show progress
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text(texts["generating"])
            start_time = time.time()
            
            # Simulate progress updates
            for i in range(steps):
                progress_bar.progress((i + 1) / steps)
                time.sleep(0.1)  # Not needed during actual generation
            
            # Generate image
            image = generate_image(pipe, prompt, negative_prompt, steps, guidance_scale)
            
            if image is not None:
                # Calculate generation time
                generation_time = time.time() - start_time
                
                # Display image
                with col2:
                    image_placeholder.image(image, caption=prompt, use_container_width=True)
                    
                    # Show information
                    info_placeholder.info(f"{texts['generation_complete']}{generation_time:.2f}s")
                    
                    # Prepare download
                    img_buffer = io.BytesIO()
                    image.save(img_buffer, format='PNG')
                    img_data = img_buffer.getvalue()
                    
                    # Download button
                    download_placeholder.download_button(
                        label=texts["download_button"],
                        data=img_data,
                        file_name=f"ai_generated_{int(time.time())}.png",
                        mime="image/png",
                        use_container_width=True
                    )
            
            # Clear progress display
            progress_bar.empty()
            status_text.empty()
    
    elif generate_button and not prompt.strip():
        st.warning(texts["prompt_warning"])
    
    # Usage instructions and examples (only show in expanded form for better UX)
    add_usage_instructions(texts)
    add_example_gallery(texts)

def add_usage_instructions(texts):
    """Add usage instructions section"""
    with st.expander(texts["usage_instructions"]):
        if texts == LANGUAGES["English"]:
            st.markdown("""
            ### How to use:
            1. **Enter description**: Describe the image you want in detail in the text box
            2. **Choose settings**: Adjust generation steps and guidance scale (optional)
            3. **Generate image**: Click the generate button and wait for AI to create the image
            4. **Download & save**: Download the image if you're satisfied with the result
            
            ### Prompt tips:
            - Use specific descriptive words, like "blue" instead of "nice color"
            - You can specify art styles, like "oil painting style", "cartoon style"
            - Add quality words, like "high quality", "detailed", "professional"
            - Describe lighting, like "soft lighting", "golden hour"
            
            ### Negative prompts:
            - Used to avoid unwanted content, like "blurry", "low quality"
            - Can avoid specific objects or styles
            """)
        elif texts == LANGUAGES["ä¸­æ–‡"]:
            st.markdown("""
            ### ä½¿ç”¨æ–¹æ³•ï¼š
            1. **è¾“å…¥æè¿°**ï¼šåœ¨æ–‡æœ¬æ¡†ä¸­è¯¦ç»†æè¿°ä½ æƒ³è¦çš„å›¾åƒ
            2. **é€‰æ‹©è®¾ç½®**ï¼šè°ƒæ•´ç”Ÿæˆæ­¥æ•°å’Œå¼•å¯¼æ¯”ä¾‹ï¼ˆå¯é€‰ï¼‰
            3. **ç”Ÿæˆå›¾åƒ**ï¼šç‚¹å‡»ç”ŸæˆæŒ‰é’®ï¼Œç­‰å¾…AIåˆ›å»ºå›¾åƒ
            4. **ä¸‹è½½ä¿å­˜**ï¼šå¦‚æœæ»¡æ„ç»“æœï¼Œå¯ä»¥ä¸‹è½½å›¾åƒ
            
            ### æç¤ºè¯æŠ€å·§ï¼š
            - ä½¿ç”¨å…·ä½“çš„æè¿°è¯ï¼Œæ¯”å¦‚"è“è‰²"è€Œä¸æ˜¯"å¥½çœ‹çš„é¢œè‰²"
            - å¯ä»¥æŒ‡å®šè‰ºæœ¯é£æ ¼ï¼Œå¦‚"æ²¹ç”»é£æ ¼"ã€"å¡é€šé£æ ¼"
            - æ·»åŠ è´¨é‡è¯ï¼Œå¦‚"é«˜è´¨é‡"ã€"è¯¦ç»†"ã€"ä¸“ä¸š"
            - æè¿°å…‰ç…§ï¼Œå¦‚"æŸ”å’Œå…‰çº¿"ã€"é»„é‡‘æ—¶å…‰"
            
            ### è´Ÿé¢æç¤ºè¯ï¼š
            - ç”¨äºé¿å…ä¸æƒ³è¦çš„å†…å®¹ï¼Œå¦‚"æ¨¡ç³Š"ã€"ä½è´¨é‡"
            - å¯ä»¥é¿å…ç‰¹å®šå¯¹è±¡æˆ–é£æ ¼
            """)
        else:  # ç²¤è¯­
            st.markdown("""
            ### ä½¿ç”¨æ–¹æ³•ï¼š
            1. **è¼¸å…¥æè¿°**ï¼šå–ºæ–‡æœ¬æ¡†å…¥é¢è©³ç´°æè¿°ä½ æƒ³è¦å˜…åœ–åƒ
            2. **æ€è¨­å®š**ï¼šèª¿æ•´ç”Ÿæˆæ­¥æ•¸åŒå¼•å°æ¯”ä¾‹ï¼ˆå¯é¸ï¼‰
            3. **ç”Ÿæˆåœ–åƒ**ï¼šã©’ç”ŸæˆæŒ‰éˆ•ï¼Œç­‰AIæ•´åœ–åƒ
            4. **ä¸‹è¼‰ä¿å­˜**ï¼šå¦‚æœæ»¿æ„çµæœï¼Œå¯ä»¥ä¸‹è¼‰åœ–åƒ
            
            ### æç¤ºè©æŠ€å·§ï¼š
            - ç”¨å…·é«”å˜…æè¿°è©ï¼Œæ¯”å¦‚"è—è‰²"è€Œå””ä¿‚"éšå˜…é¡è‰²"
            - å¯ä»¥æŒ‡å®šè—è¡“é¢¨æ ¼ï¼Œå¦‚"æ²¹ç•«é¢¨æ ¼"ã€"å¡é€šé¢¨æ ¼"
            - åŠ è³ªé‡è©ï¼Œå¦‚"é«˜è³ªé‡"ã€"è©³ç´°"ã€"å°ˆæ¥­"
            - æè¿°å…‰ç…§ï¼Œå¦‚"æŸ”å’Œå…‰ç·š"ã€"é»ƒé‡‘æ™‚å…‰"
            
            ### è² é¢æç¤ºè©ï¼š
            - ç”¨åšŸé¿å…å””æƒ³è¦å˜…å…§å®¹ï¼Œå¦‚"æ¨¡ç³Š"ã€"ä½è³ªé‡"
            - å¯ä»¥é¿å…ç‰¹å®šå°è±¡æˆ–é¢¨æ ¼
            """)

def add_example_gallery(texts):
    """Add example gallery section"""
    with st.expander(texts["example_gallery"]):
        if texts == LANGUAGES["English"]:
            st.markdown("Here are some example prompts for generation:")
            example_cols = st.columns(3)
            examples = [
                ("Landscape", "sunset over mountains, golden hour, peaceful lake reflection"),
                ("Animal", "cute red panda eating bamboo, soft fur, adorable eyes"),
                ("Art", "abstract art, colorful geometric shapes, modern style")
            ]
        elif texts == LANGUAGES["ä¸­æ–‡"]:
            st.markdown("è¿™é‡Œæ˜¯ä¸€äº›ç”Ÿæˆç¤ºä¾‹æç¤ºè¯ï¼š")
            example_cols = st.columns(3)
            examples = [
                ("é£æ™¯", "å±±å³°ä¸Šçš„æ—¥è½ï¼Œé»„é‡‘æ—¶å…‰ï¼Œå®é™çš„æ¹–é¢å€’å½±"),
                ("åŠ¨ç‰©", "å¯çˆ±çš„å°ç†ŠçŒ«åƒç«¹å­ï¼ŒæŸ”è½¯çš„æ¯›å‘ï¼Œadorableçœ¼ç›"),
                ("è‰ºæœ¯", "æŠ½è±¡è‰ºæœ¯ï¼Œå½©è‰²å‡ ä½•å½¢çŠ¶ï¼Œç°ä»£é£æ ¼")
            ]
        else:  # ç²¤è¯­
            st.markdown("å‘¢åº¦ä¿‚ä¸€å•²ç”Ÿæˆç¤ºä¾‹æç¤ºè©ï¼š")
            example_cols = st.columns(3)
            examples = [
                ("é¢¨æ™¯", "å±±å³°ä¸Šå˜…æ—¥è½ï¼Œé»ƒé‡‘æ™‚å…‰ï¼Œå¯§éœå˜…æ¹–é¢å€’å½±"),
                ("å‹•ç‰©", "å¯æ„›å˜…å°ç†Šè²“é£Ÿç«¹å­ï¼ŒæŸ”è»Ÿå˜…æ¯›é«®ï¼Œadorableçœ¼ç›"),
                ("è—è¡“", "æŠ½è±¡è—è¡“ï¼Œå½©è‰²å¹¾ä½•å½¢ç‹€ï¼Œç¾ä»£é¢¨æ ¼")
            ]
        
        for i, (title, example_prompt) in enumerate(examples):
            with example_cols[i]:
                st.markdown(f"**{title}**")
                st.code(example_prompt, language=None)

if __name__ == "__main__":
    main()