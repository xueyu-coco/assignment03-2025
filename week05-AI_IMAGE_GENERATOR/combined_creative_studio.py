import streamlit as st
import torch
from diffusers import AutoPipelineForText2Image, LCMScheduler
from streamlit_webrtc import webrtc_streamer
import av
import cv2
import numpy as np
from PIL import Image, ImageDraw
import io
import base64
import os
import time

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI Creative Studio",
    page_icon="ğŸ¨",
    layout="wide"
)

# åˆå§‹åŒ–session state
if "pipeline" not in st.session_state:
    st.session_state["pipeline"] = None
    st.session_state["pipeline_loaded"] = False

if "generated_images" not in st.session_state:
    st.session_state["generated_images"] = []

if "selected_overlay_image" not in st.session_state:
    st.session_state["selected_overlay_image"] = None

# ä¸»æ ‡é¢˜
st.title("ğŸ¨ AI Creative Studio")
st.markdown("### é›†æˆå›¾ç‰‡ç”Ÿæˆä¸è§†é¢‘åˆæˆçš„åˆ›æ„å·¥å…·")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ åŠŸèƒ½é€‰æ‹©")
    
    # åŠŸèƒ½é€‰æ‹©
    feature_mode = st.selectbox(
        "é€‰æ‹©åŠŸèƒ½æ¨¡å¼",
        ["ğŸ¨ å›¾ç‰‡ç”Ÿæˆ", "ğŸ“¹ è§†é¢‘æ»¤é•œ", "ğŸ”„ å›¾ç‰‡+è§†é¢‘åˆæˆ"]
    )
    
    st.markdown("---")
    
    # GPUçŠ¶æ€
    st.subheader("ğŸ’» ç³»ç»ŸçŠ¶æ€")
    if torch.cuda.is_available():
        st.success(f"GPU: {torch.cuda.get_device_name(0)}")
        st.info(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    else:
        st.warning("ä½¿ç”¨CPUæ¨¡å¼")
    
    st.markdown("---")
    
    # ç”Ÿæˆçš„å›¾ç‰‡åº“
    st.subheader("ğŸ–¼ï¸ å›¾ç‰‡åº“")
    if st.session_state["generated_images"]:
        st.write(f"å·²ç”Ÿæˆ {len(st.session_state['generated_images'])} å¼ å›¾ç‰‡")
        
        # æ˜¾ç¤ºæœ€è¿‘çš„3å¼ å›¾ç‰‡ç¼©ç•¥å›¾
        for i, img in enumerate(st.session_state["generated_images"][-3:]):
            with st.container():
                st.image(img, caption=f"å›¾ç‰‡ {len(st.session_state['generated_images'])-2+i}", width=150)
                if st.button(f"ç”¨ä½œè§†é¢‘æ»¤é•œ", key=f"use_img_{i}"):
                    st.session_state["selected_overlay_image"] = img
                    st.success("å·²é€‰æ‹©ä¸ºè§†é¢‘æ»¤é•œå›¾ç‰‡")
        
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå›¾ç‰‡åº“"):
            st.session_state["generated_images"] = []
            st.rerun()
    else:
        st.info("æš‚æ— ç”Ÿæˆçš„å›¾ç‰‡")

# åŠ è½½AIæ¨¡å‹çš„å‡½æ•°
@st.cache_resource
def load_image_pipeline():
    """åŠ è½½å›¾ç‰‡ç”Ÿæˆæ¨¡å‹"""
    try:
        model = 'lykon/dreamshaper-8-lcm'
        pipe = AutoPipelineForText2Image.from_pretrained(
            model, 
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
        )
        pipe.to("cuda" if torch.cuda.is_available() else "cpu")
        pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)
        return pipe
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

# åˆ›å»ºé»˜è®¤è¦†ç›–å›¾åƒ
def create_default_overlay(size=(100, 100)):
    """åˆ›å»ºé»˜è®¤çš„è¦†ç›–å›¾åƒ"""
    img = Image.new('RGBA', size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    # ç»˜åˆ¶ä¸€ä¸ªç®€å•çš„ç¬‘è„¸
    center = (size[0]//2, size[1]//2)
    radius = min(size) // 3
    
    # è„¸éƒ¨ (é»„è‰²åœ†åœˆ)
    draw.ellipse([
        center[0] - radius, center[1] - radius,
        center[0] + radius, center[1] + radius
    ], fill=(255, 255, 0, 200))
    
    # çœ¼ç›
    eye_size = radius // 4
    draw.ellipse([
        center[0] - radius//2 - eye_size//2, center[1] - radius//3 - eye_size//2,
        center[0] - radius//2 + eye_size//2, center[1] - radius//3 + eye_size//2
    ], fill=(0, 0, 0, 255))
    
    draw.ellipse([
        center[0] + radius//2 - eye_size//2, center[1] - radius//3 - eye_size//2,
        center[0] + radius//2 + eye_size//2, center[1] - radius//3 + eye_size//2
    ], fill=(0, 0, 0, 255))
    
    # å˜´å·´
    mouth_width = radius
    draw.arc([
        center[0] - mouth_width//2, center[1],
        center[0] + mouth_width//2, center[1] + radius//2
    ], start=0, end=180, fill=(0, 0, 0, 255), width=3)
    
    return img

# å›¾åƒè¦†ç›–å‡½æ•°
def overlay_image_on_frame(frame_img, overlay_img, x, y, scale=1.0):
    """åœ¨è§†é¢‘å¸§ä¸Šè¦†ç›–å›¾åƒ"""
    if overlay_img is None:
        return frame_img
    
    # è½¬æ¢PILå›¾åƒä¸ºnumpyæ•°ç»„
    if isinstance(overlay_img, Image.Image):
        overlay_array = np.array(overlay_img)
    else:
        overlay_array = overlay_img
    
    # è°ƒæ•´è¦†ç›–å›¾åƒå¤§å°
    img_height, img_width = overlay_array.shape[:2]
    new_height = int(img_height * scale)
    new_width = int(img_width * scale)
    
    if new_height <= 0 or new_width <= 0:
        return frame_img
    
    # ç¼©æ”¾å›¾åƒ
    resized_img = cv2.resize(overlay_array, (new_width, new_height))
    
    # ç¡®ä¿åæ ‡åœ¨å›¾åƒè¾¹ç•Œå†…
    y1 = max(0, y - new_height // 2)
    y2 = min(frame_img.shape[0], y1 + new_height)
    x1 = max(0, x - new_width // 2)
    x2 = min(frame_img.shape[1], x1 + new_width)
    
    # è°ƒæ•´è¦†ç›–åŒºåŸŸ
    actual_height = y2 - y1
    actual_width = x2 - x1
    
    if actual_height <= 0 or actual_width <= 0:
        return frame_img
    
    img_roi = resized_img[:actual_height, :actual_width]
    
    # å¤„ç†é€æ˜åº¦
    if img_roi.shape[2] == 4:  # RGBA
        alpha = img_roi[:, :, 3] / 255.0
        for c in range(3):  # BGR
            frame_img[y1:y2, x1:x2, c] = (
                alpha * img_roi[:, :, c] + 
                (1 - alpha) * frame_img[y1:y2, x1:x2, c]
            )
    else:  # RGB
        frame_img[y1:y2, x1:x2] = img_roi[:, :, :3]
    
    return frame_img

# è§†é¢‘å¸§å¤„ç†å›è°ƒ
def video_frame_callback(frame):
    img = frame.to_ndarray(format="bgr24")
    
    # è·å–è¦†ç›–å›¾åƒ
    overlay_img = st.session_state.get("selected_overlay_image")
    
    if overlay_img is None:
        # ä½¿ç”¨é»˜è®¤å›¾åƒ
        overlay_img = create_default_overlay((80, 80))
    
    try:
        # äººè„¸æ£€æµ‹
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 4)
        
        # åœ¨æ¯ä¸ªæ£€æµ‹åˆ°çš„äººè„¸ä½ç½®æ·»åŠ è¦†ç›–å›¾åƒ
        for (x, y, w, h) in faces:
            center_x = x + w // 2
            center_y = y + h // 2
            scale = w / 100.0
            
            img = overlay_image_on_frame(img, overlay_img, center_x, center_y, scale)
    
    except Exception as e:
        # å¦‚æœäººè„¸æ£€æµ‹å¤±è´¥ï¼Œåœ¨å±å¹•ä¸­å¤®æ·»åŠ å›¾åƒ
        center_x = img.shape[1] // 2
        center_y = img.shape[0] // 2
        img = overlay_image_on_frame(img, overlay_img, center_x, center_y, 1.0)
    
    return av.VideoFrame.from_ndarray(img, format="bgr24")

# ä¸»è¦å†…å®¹åŒºåŸŸ
if feature_mode == "ğŸ¨ å›¾ç‰‡ç”Ÿæˆ":
    # å›¾ç‰‡ç”Ÿæˆæ¨¡å¼
    st.header("ğŸ¨ AIå›¾ç‰‡ç”Ÿæˆ")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“ è¾“å…¥æè¿°")
        
        # é¢„è®¾æç¤ºè¯
        preset_prompts = {
            "é€‰æ‹©é¢„è®¾...": "",
            "å¯çˆ±åŠ¨ç‰©": "cute fluffy puppy playing in garden, soft lighting, adorable",
            "ç¾ä¸½é£æ™¯": "beautiful landscape with mountains, lakes, golden hour lighting",
            "ç§‘å¹»åœºæ™¯": "futuristic cityscape with flying cars, neon lights, cyberpunk style",
            "è‰ºæœ¯è‚–åƒ": "portrait of wise wizard, detailed face, magical atmosphere, fantasy art",
            "å¡é€šé£æ ¼": "cartoon style illustration, colorful, friendly, animated character"
        }
        
        selected_preset = st.selectbox("é¢„è®¾æç¤ºè¯", list(preset_prompts.keys()))
        
        # ä¸»è¦æç¤ºè¯è¾“å…¥
        if selected_preset != "é€‰æ‹©é¢„è®¾...":
            default_prompt = preset_prompts[selected_preset]
        else:
            default_prompt = ""
        
        prompt = st.text_area(
            "å›¾ç‰‡æè¿° (Prompt)",
            value=default_prompt,
            height=100,
            help="è¯¦ç»†æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„å›¾ç‰‡"
        )
        
        # ç”Ÿæˆå‚æ•°
        col_param1, col_param2 = st.columns(2)
        with col_param1:
            num_steps = st.slider("æ¨ç†æ­¥æ•°", 4, 20, 8)
        with col_param2:
            guidance_scale = st.slider("å¼•å¯¼å¼ºåº¦", 1.0, 5.0, 2.0, 0.5)
        
        # ç”ŸæˆæŒ‰é’®
        generate_btn = st.button("ğŸ¨ ç”Ÿæˆå›¾ç‰‡", type="primary", use_container_width=True)
    
    with col2:
        st.subheader("ğŸ–¼ï¸ ç”Ÿæˆç»“æœ")
        
        if generate_btn and prompt.strip():
            # åŠ è½½æ¨¡å‹
            if not st.session_state["pipeline_loaded"]:
                with st.spinner("æ­£åœ¨åŠ è½½AIæ¨¡å‹..."):
                    pipeline = load_image_pipeline()
                    if pipeline:
                        st.session_state["pipeline"] = pipeline
                        st.session_state["pipeline_loaded"] = True
                        st.success("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
                    else:
                        st.error("æ¨¡å‹åŠ è½½å¤±è´¥")
                        st.stop()
            
            # ç”Ÿæˆå›¾ç‰‡
            if st.session_state["pipeline"]:
                with st.spinner("æ­£åœ¨ç”Ÿæˆå›¾ç‰‡..."):
                    try:
                        start_time = time.time()
                        
                        images = st.session_state["pipeline"](
                            prompt,
                            num_inference_steps=num_steps,
                            guidance_scale=guidance_scale,
                            num_images_per_prompt=1
                        ).images
                        
                        generation_time = time.time() - start_time
                        
                        # ä¿å­˜åˆ°session state
                        for image in images:
                            st.session_state["generated_images"].append(image)
                        
                        # æ˜¾ç¤ºç”Ÿæˆçš„å›¾ç‰‡
                        for image in images:
                            st.image(image, caption=prompt, use_container_width=True)
                        
                        st.success(f"âœ… ç”Ÿæˆå®Œæˆï¼ç”¨æ—¶: {generation_time:.2f}ç§’")
                        
                        # æ·»åŠ ä¸‹è½½æŒ‰é’®
                        img_buffer = io.BytesIO()
                        images[0].save(img_buffer, format='PNG')
                        img_data = img_buffer.getvalue()
                        
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½å›¾ç‰‡",
                            data=img_data,
                            file_name=f"ai_generated_{int(time.time())}.png",
                            mime="image/png",
                            use_container_width=True
                        )
                        
                    except Exception as e:
                        st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
        
        elif generate_btn and not prompt.strip():
            st.warning("è¯·è¾“å…¥å›¾ç‰‡æè¿°")
        
        # æ˜¾ç¤ºæœ€è¿‘ç”Ÿæˆçš„å›¾ç‰‡
        if st.session_state["generated_images"]:
            st.markdown("### æœ€è¿‘ç”Ÿæˆçš„å›¾ç‰‡")
            latest_image = st.session_state["generated_images"][-1]
            st.image(latest_image, use_container_width=True)

elif feature_mode == "ğŸ“¹ è§†é¢‘æ»¤é•œ":
    # è§†é¢‘æ»¤é•œæ¨¡å¼
    st.header("ğŸ“¹ å®æ—¶è§†é¢‘æ»¤é•œ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“· æ‘„åƒå¤´é¢„è§ˆ")
        
        # è§†é¢‘æµç»„ä»¶
        webrtc_streamer(
            key="video_filter",
            video_frame_callback=video_frame_callback,
            rtc_configuration={
                "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
            }
        )
    
    with col2:
        st.subheader("ğŸ­ æ»¤é•œè®¾ç½®")
        
        # æ˜¾ç¤ºå½“å‰é€‰æ‹©çš„è¦†ç›–å›¾åƒ
        if st.session_state["selected_overlay_image"]:
            st.write("å½“å‰æ»¤é•œå›¾ç‰‡:")
            st.image(st.session_state["selected_overlay_image"], width=150)
            
            if st.button("ğŸ—‘ï¸ ç§»é™¤æ»¤é•œå›¾ç‰‡"):
                st.session_state["selected_overlay_image"] = None
                st.rerun()
        else:
            st.info("ä½¿ç”¨é»˜è®¤ç¬‘è„¸æ»¤é•œ")
            default_img = create_default_overlay((100, 100))
            st.image(default_img, width=150)
        
        st.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. ç‚¹å‡» **START** å¯åŠ¨æ‘„åƒå¤´
        2. å…è®¸æµè§ˆå™¨è®¿é—®æ‘„åƒå¤´æƒé™
        3. é¢å‘æ‘„åƒå¤´ï¼Œåº”ç”¨ä¼šè‡ªåŠ¨æ£€æµ‹äººè„¸
        4. æ»¤é•œå›¾ç‰‡ä¼šè¦†ç›–åœ¨æ£€æµ‹åˆ°çš„äººè„¸ä½ç½®
        5. ä»å›¾ç‰‡åº“é€‰æ‹©è‡ªå®šä¹‰æ»¤é•œå›¾ç‰‡
        """)

else:  # å›¾ç‰‡+è§†é¢‘åˆæˆæ¨¡å¼
    # åˆæˆæ¨¡å¼
    st.header("ğŸ”„ å›¾ç‰‡ç”Ÿæˆ + è§†é¢‘æ»¤é•œåˆæˆ")
    
    # ä¸ŠåŠéƒ¨åˆ†ï¼šå›¾ç‰‡ç”Ÿæˆ
    st.subheader("ğŸ¨ ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæ»¤é•œå›¾ç‰‡")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # å¿«é€Ÿç”Ÿæˆé¢„è®¾
        quick_prompts = {
            "ğŸ¶ å¡é€šç‹—ç‹—": "cute cartoon dog head, friendly smile, colorful, simple design",
            "ğŸ± å¯çˆ±çŒ«å’ª": "adorable cartoon cat face, big eyes, cute expression, pastel colors",
            "ğŸ¦„ ç‹¬è§’å…½": "magical unicorn head, rainbow mane, sparkles, fantasy style",
            "ğŸ» æ³°è¿ªç†Š": "teddy bear face, brown fur, cute button nose, friendly expression",
            "ğŸ‘‘ çš‡å† ": "golden crown, jewels, royal, elegant design",
            "ğŸ­ é¢å…·": "venetian carnival mask, decorative, colorful patterns"
        }
        
        st.write("å¿«é€Ÿç”Ÿæˆæ»¤é•œå›¾ç‰‡:")
        
        for prompt_name, prompt_text in quick_prompts.items():
            if st.button(prompt_name, use_container_width=True):
                # åŠ è½½æ¨¡å‹å¹¶ç”Ÿæˆ
                if not st.session_state["pipeline_loaded"]:
                    with st.spinner("æ­£åœ¨åŠ è½½AIæ¨¡å‹..."):
                        pipeline = load_image_pipeline()
                        if pipeline:
                            st.session_state["pipeline"] = pipeline
                            st.session_state["pipeline_loaded"] = True
                
                if st.session_state["pipeline"]:
                    with st.spinner(f"æ­£åœ¨ç”Ÿæˆ{prompt_name}..."):
                        try:
                            images = st.session_state["pipeline"](
                                prompt_text,
                                num_inference_steps=8,
                                guidance_scale=2.0,
                                num_images_per_prompt=1
                            ).images
                            
                            # ä¿å­˜å¹¶é€‰æ‹©ä¸ºæ»¤é•œ
                            for image in images:
                                st.session_state["generated_images"].append(image)
                                st.session_state["selected_overlay_image"] = image
                            
                            st.success(f"âœ… {prompt_name} ç”Ÿæˆå®Œæˆå¹¶å·²è®¾ä¸ºæ»¤é•œï¼")
                            st.rerun()
                            
                        except Exception as e:
                            st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
    
    with col2:
        # è‡ªå®šä¹‰æç¤ºè¯
        st.write("æˆ–è¾“å…¥è‡ªå®šä¹‰æè¿°:")
        custom_prompt = st.text_input("å›¾ç‰‡æè¿°", placeholder="ä¾‹å¦‚: å¯çˆ±çš„å°åŠ¨ç‰©å¤´åƒ")
        
        if st.button("ğŸ¨ ç”Ÿæˆè‡ªå®šä¹‰æ»¤é•œ") and custom_prompt.strip():
            # åŒæ ·çš„ç”Ÿæˆé€»è¾‘
            if not st.session_state["pipeline_loaded"]:
                with st.spinner("æ­£åœ¨åŠ è½½AIæ¨¡å‹..."):
                    pipeline = load_image_pipeline()
                    if pipeline:
                        st.session_state["pipeline"] = pipeline
                        st.session_state["pipeline_loaded"] = True
            
            if st.session_state["pipeline"]:
                with st.spinner("æ­£åœ¨ç”Ÿæˆå›¾ç‰‡..."):
                    try:
                        images = st.session_state["pipeline"](
                            custom_prompt,
                            num_inference_steps=8,
                            guidance_scale=2.0,
                            num_images_per_prompt=1
                        ).images
                        
                        for image in images:
                            st.session_state["generated_images"].append(image)
                            st.session_state["selected_overlay_image"] = image
                        
                        st.success("âœ… è‡ªå®šä¹‰æ»¤é•œç”Ÿæˆå®Œæˆï¼")
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
    
    st.markdown("---")
    
    # ä¸‹åŠéƒ¨åˆ†ï¼šè§†é¢‘æ»¤é•œ
    st.subheader("ğŸ“¹ ç¬¬äºŒæ­¥ï¼šåº”ç”¨è§†é¢‘æ»¤é•œ")
    
    col3, col4 = st.columns([2, 1])
    
    with col3:
        # è§†é¢‘æµ
        webrtc_streamer(
            key="combined_filter",
            video_frame_callback=video_frame_callback,
            rtc_configuration={
                "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
            }
        )
    
    with col4:
        st.write("å½“å‰æ»¤é•œ:")
        if st.session_state["selected_overlay_image"]:
            st.image(st.session_state["selected_overlay_image"], width=150)
            st.success("âœ… ä½¿ç”¨AIç”Ÿæˆçš„æ»¤é•œå›¾ç‰‡")
        else:
            default_img = create_default_overlay((100, 100))
            st.image(default_img, width=150)
            st.info("ä½¿ç”¨é»˜è®¤æ»¤é•œ")

# é¡µè„š
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
<p>ğŸ¨ AI Creative Studio | å›¾ç‰‡ç”Ÿæˆ + è§†é¢‘æ»¤é•œåˆæˆå·¥å…·</p>
<p>ä½¿ç”¨ Stable Diffusion + OpenCV + WebRTC æŠ€æœ¯</p>
</div>
""", unsafe_allow_html=True)